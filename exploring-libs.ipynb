{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import epitran\n",
    "import nlp\n",
    "from nlp import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlp.load:Checking /home/dwija/.cache/huggingface/datasets/446620b7923384a434ce127dd59e7c03a3236dc3b1ca70ec3c610d054206ab32.789f5ff24f92df60a617ad13254925cf45778e87aa991842ac1b2cf1bf4755f8.py for additional imports.\n",
      "INFO:filelock:Lock 139932284177664 acquired on /home/dwija/.cache/huggingface/datasets/446620b7923384a434ce127dd59e7c03a3236dc3b1ca70ec3c610d054206ab32.789f5ff24f92df60a617ad13254925cf45778e87aa991842ac1b2cf1bf4755f8.py.lock\n",
      "INFO:nlp.load:Found main folder for dataset https://s3.amazonaws.com/datasets.huggingface.co/nlp/datasets/lince/lince.py at /home/dwija/anaconda3/envs/cs/lib/python3.8/site-packages/nlp/datasets/lince\n",
      "INFO:nlp.load:Found specific version folder for dataset https://s3.amazonaws.com/datasets.huggingface.co/nlp/datasets/lince/lince.py at /home/dwija/anaconda3/envs/cs/lib/python3.8/site-packages/nlp/datasets/lince/595160710bba5b1344b3aedf351d4567d486058a9f22c32c08f8405fe81184b8\n",
      "INFO:nlp.load:Found script file from https://s3.amazonaws.com/datasets.huggingface.co/nlp/datasets/lince/lince.py to /home/dwija/anaconda3/envs/cs/lib/python3.8/site-packages/nlp/datasets/lince/595160710bba5b1344b3aedf351d4567d486058a9f22c32c08f8405fe81184b8/lince.py\n",
      "INFO:nlp.load:Found dataset infos file from https://s3.amazonaws.com/datasets.huggingface.co/nlp/datasets/lince/dataset_infos.json to /home/dwija/anaconda3/envs/cs/lib/python3.8/site-packages/nlp/datasets/lince/595160710bba5b1344b3aedf351d4567d486058a9f22c32c08f8405fe81184b8/dataset_infos.json\n",
      "INFO:nlp.load:Found metadata file for dataset https://s3.amazonaws.com/datasets.huggingface.co/nlp/datasets/lince/lince.py at /home/dwija/anaconda3/envs/cs/lib/python3.8/site-packages/nlp/datasets/lince/595160710bba5b1344b3aedf351d4567d486058a9f22c32c08f8405fe81184b8/lince.json\n",
      "INFO:filelock:Lock 139932284177664 released on /home/dwija/.cache/huggingface/datasets/446620b7923384a434ce127dd59e7c03a3236dc3b1ca70ec3c610d054206ab32.789f5ff24f92df60a617ad13254925cf45778e87aa991842ac1b2cf1bf4755f8.py.lock\n",
      "INFO:nlp.info:Loading Dataset Infos from /home/dwija/anaconda3/envs/cs/lib/python3.8/site-packages/nlp/datasets/lince/595160710bba5b1344b3aedf351d4567d486058a9f22c32c08f8405fe81184b8\n",
      "INFO:nlp.builder:Overwrite dataset info from restored data version.\n",
      "INFO:nlp.info:Loading Dataset info from /home/dwija/.cache/huggingface/datasets/lince/ner_hineng/1.0.0/595160710bba5b1344b3aedf351d4567d486058a9f22c32c08f8405fe81184b8\n",
      "INFO:nlp.builder:Reusing dataset lince (/home/dwija/.cache/huggingface/datasets/lince/ner_hineng/1.0.0/595160710bba5b1344b3aedf351d4567d486058a9f22c32c08f8405fe81184b8)\n",
      "INFO:nlp.builder:Constructing Dataset for split train, validation, test, from /home/dwija/.cache/huggingface/datasets/lince/ner_hineng/1.0.0/595160710bba5b1344b3aedf351d4567d486058a9f22c32c08f8405fe81184b8\n",
      "INFO:nlp.utils.info_utils:All the checksums matched successfully for post processing resources\n",
      "INFO:nlp.utils.info_utils:All the checksums matched successfully for post processing resources\n",
      "INFO:nlp.utils.info_utils:All the checksums matched successfully for post processing resources\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\n",
    "   'lince', 'ner_hineng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from epitran.backoff import Backoff\n",
    "b = Backoff(['hin-Deva', 'eng-Latn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zaːɡaːn, pəʃt͡ʃimiː polæːnɖə men ek ʃəɦər ɦæː। jəɦ ʃəɦər bobər nədiː ke kinaːre stʰit ɦæː। 2004 ke d͡ʒənɡəɳnaː ke anusaːr jəɦãː kiː aːbaːdiː 26665 ɦæː। jəɦ ʃəɦər zaːɡaːn prədeʃ kiː raːd͡ʒd̤aːniː ɦæː। aɖolfə enɡler renɦolɖə roeɦr̩t͡ʃtə volpʰəɡaːŋɡə saːmuel lukszə ɡərɡula dunsə, skɔʈlæːnɖə netpʰen, d͡ʒərməniː ortrəndə, d͡ʒərməniː telto, d͡ʒərməniː'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.transliterate('ज़ागान, पश्चिमी पोलैंड में एक शहर है। यह शहर बोबर नदी के किनारे स्थित है। 2004 के जनगणना के अनुसार यहाँ की आबादी 26665 है। यह शहर ज़ागान प्रदेश की राजधानी है। अडोल्फ़ एन्ग्लेर रेंहोल्ड रोएहृच्त वोल्फगांग सामुएल लुकस्ज़ गर्गुलअ दुन्स, स्कॉटलैंड नेत्फेन, जर्मनी ओरत्रंद, जर्मनी तेल्तो, जर्मनी')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aj dɪd ɪt bʌt fɪɹ baj'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.transliterate('I did it but feer bhi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aj dɪd ɪt bʌt fɹ baj'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.transliterate('I did it but phir bhi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aj dɪd ɪt bʌt fɹ̩ baj'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.transliterate('I did it but fir bhi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': Dataset(features: {'idx': Value(dtype='int32', id=None), 'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'lid': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'ner': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)}, num_rows: 1243), 'validation': Dataset(features: {'idx': Value(dtype='int32', id=None), 'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'lid': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'ner': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)}, num_rows: 314), 'test': Dataset(features: {'idx': Value(dtype='int32', id=None), 'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'lid': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'ner': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)}, num_rows: 522)}\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['train']['lid'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner=[]\n",
    "\n",
    "for i in range(20):\n",
    "    hin=[]\n",
    "    trans=[]\n",
    "    lid=\", \".join(dataset['train']['lid'][i])\n",
    "    sentence=\", \".join(dataset['train']['tokens'][i])\n",
    "    for j in range(len(dataset['train']['lid'][i])):\n",
    "        if dataset['train']['lid'][i][j]==\"hi\":\n",
    "            hin.append(dataset['train']['tokens'][i][j])\n",
    "            trans.append(b.transliterate(dataset['train']['tokens'][i][j]))\n",
    "    hin=\", \".join(hin)\n",
    "    trans=\", \".join(trans)\n",
    "    ner.append([sentence,lid,hin,trans])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ab, yeh, kon, Bol, raha, hai, Aaj, #MahaShivratri, pe, Aap, wale, Delhi, me, WiFi, ke, sath, 30, min, Weed, bhi, free, de, rahe, hai, #',\n",
       " 'hi, hi, hi, hi, hi, hi, hi, rest, hi, hi, hi, rest, hi, hi, hi, hi, rest, en, en, hi, en, hi, hi, hi, rest',\n",
       " 'Ab, yeh, kon, Bol, raha, hai, Aaj, pe, Aap, wale, me, WiFi, ke, sath, bhi, de, rahe, hai',\n",
       " 'æb, jɛ, kɑn, bɑl, ɹɑhə, haj, æ, pi, æp, wejl, mi, wajfaj, ki, sæθ, baj, di, ɹejhi, haj']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ner.tsv\",\"w+\") as file:\n",
    "    for i in ner:\n",
    "        file.write((i[0])+\"\\t\"+(i[1])+\"\\t\"+(i[2])+\"\\t\"+(i[3])+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs",
   "language": "python",
   "name": "cs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
